{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/mich/anaconda/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#%env CUDA_DEVICE_ORDER=1\n",
    "#%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM, Merge\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 703243629779452021\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train = pd.read_pickle(\"./data/df_train.pkl\")\n",
    "#df_test = pd.read_pickle(\"./data/df_test.pkl\")\n",
    "\n",
    "token_train = pd.read_pickle(\"./data/token_train.pkl\")\n",
    "token_test = pd.read_pickle(\"./data/token_test.pkl\")\n",
    "\n",
    "#vec_train = pd.read_pickle(\"./data/vec_train_glove.pkl\")\n",
    "#vec_test = pd.read_pickle(\"./data/vec_test_glove.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "googlenews_embedding = './data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(googlenews_embedding, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mich/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:28: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "vocabulary = dict()\n",
    "inverse_vocabulary = ['<unk>']\n",
    "stops = set(stopwords.words('english'))\n",
    "questions = ['tokenq1', 'tokenq2']\n",
    "\n",
    "# Iterate over the questions of both training and test datasets\n",
    "for dataset in [token_train, token_test]:\n",
    "    for index, row in dataset.iterrows():\n",
    "\n",
    "        # Iterate through the text of both questions of the row\n",
    "        for question in questions:\n",
    "\n",
    "            question_to_number = []  # q2n -> question numbers representation\n",
    "            for word in row[question]:\n",
    "\n",
    "                # Check for unwanted words\n",
    "                if word in stops and word not in word2vec.vocab:\n",
    "                    continue\n",
    "\n",
    "                if word not in vocabulary:\n",
    "                    vocabulary[word] = len(inverse_vocabulary)\n",
    "                    question_to_number.append(len(inverse_vocabulary))\n",
    "                    inverse_vocabulary.append(word)\n",
    "                else:\n",
    "                    question_to_number.append(vocabulary[word])\n",
    "\n",
    "            # Replace questions as word to question as number representation\n",
    "            dataset.set_value(index, question, question_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_train.to_pickle('./data/word2vec_train.pkl')\n",
    "token_test.to_pickle('./data/word2vec_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the embedding matrix\n",
    "embedding_dim = 300\n",
    "embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  # This will be the embedding matrix\n",
    "embeddings[0] = 0  # So that the padding will be ignored\n",
    "\n",
    "for word, index in vocabulary.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embeddings[index] = word2vec.word_vec(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split to train validation\n",
    "validation_size = 40000\n",
    "training_size = len(token_train) - validation_size\n",
    "\n",
    "question_cols = token_train[['tokenq1', 'tokenq2']]\n",
    "duplicate = token_train['is_duplicate']\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(question_cols, duplicate, test_size=validation_size)\n",
    "\n",
    "# Split to dicts\n",
    "X_train = {'left': X_train.tokenq1, 'right': X_train.tokenq2}\n",
    "X_validation = {'left': X_validation.tokenq1, 'right': X_validation.tokenq2}\n",
    "X_test = {'left': token_test.tokenq1, 'right': token_test.tokenq1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert labels to their numpy representations\n",
    "Y_train = Y_train.values\n",
    "Y_validation = Y_validation.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'left': 297432                              [1, 1710, 17366, 2, 80]\n",
       " 309380                        [22, 3, 1999, 18, 1071, 4282]\n",
       " 186853          [1, 115, 3, 346, 1081, 558, 7783, 175, 688]\n",
       " 137620                    [22, 94, 24, 287, 92, 8353, 7611]\n",
       " 249535         [1, 2, 288, 2471, 2640, 159, 3, 1136, 52645]\n",
       " 10680       [2, 44, 454, 1940, 49, 5647, 8, 3, 11318, 1308]\n",
       " 174864               [81, 24, 119, 27, 1728, 24, 139, 1347]\n",
       " 136616                               [2, 3615, 57059, 2157]\n",
       " 71193               [269, 971, 5866, 352, 1055, 1056, 5318]\n",
       " 264191                           [23, 3183, 8311, 768, 499]\n",
       " 301288    [38, 94, 187, 305, 2655, 9241, 5193, 115, 148,...\n",
       " 19915                    [22, 94, 24, 412, 4944, 88, 19865]\n",
       " 261693                                   [1, 2, 6329, 2401]\n",
       " 139222    [22, 23, 24, 97, 49, 662, 3218, 159, 3, 195, 3...\n",
       " 191259       [23, 305, 315, 2299, 3803, 8097, 3, 195, 9640]\n",
       " 45492                                [22, 94, 24, 103, 190]\n",
       " 99002             [1, 2, 154, 5, 48735, 11704, 8, 18, 8213]\n",
       " 135830    [22, 300, 1273, 1274, 1061, 300, 821, 421, 103...\n",
       " 173990    [24, 421, 2857, 54, 107, 1887, 3013, 17, 44, 2...\n",
       " 134638                     [22, 94, 24, 27, 25, 8208, 1903]\n",
       " 226411    [27, 10168, 20332, 682, 2392, 33, 1522, 502, 3...\n",
       " 240245                     [22, 23, 24, 991, 989, 359, 992]\n",
       " 19535     [373, 115, 116, 4637, 5435, 449, 2742, 8826, 1...\n",
       " 63937                                    [22, 81, 24, 1409]\n",
       " 47687                         [22, 23, 24, 130, 1144, 3127]\n",
       " 156253                        [1, 94, 96, 267, 1064, 8, 11]\n",
       " 266620    [22, 168, 1301, 81, 24, 1409, 2191, 197, 1703,...\n",
       " 142707        [38, 72, 4753, 141, 159, 141, 8, 5447, 18986]\n",
       " 112497    [22, 346, 72, 44, 271, 873, 54, 107, 1988, 175...\n",
       " 289411               [22, 4588, 94, 96, 421, 2065, 8, 4081]\n",
       "                                 ...                        \n",
       " 299936    [47, 24, 2418, 4635, 24, 1181, 37508, 862, 364...\n",
       " 302882    [1, 94, 24, 94, 159, 27, 66214, 4361, 47, 1949...\n",
       " 158                [22, 94, 96, 271, 1052, 175, 1053, 1054]\n",
       " 37680                          [22, 94, 24, 1364, 27, 2445]\n",
       " 306240                   [22, 2, 3, 512, 12399, 177, 8, 11]\n",
       " 223217               [1, 94, 341, 4921, 192, 451, 1107, 94]\n",
       " 92704                             [22, 619, 18, 31292, 936]\n",
       " 159586                     [1, 115, 116, 407, 159, 95, 972]\n",
       " 187839                   [22, 23, 24, 7318, 288, 919, 9320]\n",
       " 102353    [7998, 1890, 10824, 10825, 366, 49, 10826, 172...\n",
       " 87443                               [1, 3708, 72, 169, 760]\n",
       " 143003    [22, 23, 833, 5620, 128, 3, 2862, 3197, 88, 7940]\n",
       " 269533              [38, 9118, 115, 448, 823, 8, 872, 5717]\n",
       " 16587             [38, 115, 172, 75, 11, 167, 1537, 8, 169]\n",
       " 122586    [53, 2, 375, 3129, 5727, 22816, 286, 5727, 54219]\n",
       " 291397                 [1, 2, 288, 132, 219, 130, 220, 221]\n",
       " 293272                     [1, 115, 3, 180, 122, 108, 2263]\n",
       " 305930                                [22, 2, 3, 84124, 19]\n",
       " 302181    [94, 96, 267, 18, 4020, 2372, 4019, 3, 339, 10...\n",
       " 193936    [94, 4163, 128, 10506, 460, 2724, 1993, 1907, 19]\n",
       " 115103      [1, 2, 3, 2928, 44339, 3970, 1909, 44339, 4738]\n",
       " 76677     [94, 96, 1585, 267, 3831, 2, 3, 180, 129, 6363...\n",
       " 3206          [1, 2, 3, 180, 872, 5278, 1361, 108, 80, 293]\n",
       " 17329                      [1, 2, 44, 139, 421, 1755, 1809]\n",
       " 191622    [1, 2, 3, 1684, 3, 3542, 26180, 2016, 8, 3, 59...\n",
       " 165744    [22, 134, 1059, 8, 54, 282, 50, 107, 474, 489,...\n",
       " 279941    [22, 94, 96, 315, 4526, 286, 3506, 1007, 108, ...\n",
       " 135461      [1, 2, 3, 1515, 30166, 36, 3, 49, 17163, 18986]\n",
       " 217091    [1, 2, 3, 180, 219, 1361, 159, 527, 150, 17, 3...\n",
       " 141662    [2, 44, 1497, 76, 286, 962, 463, 267, 15418, 2...\n",
       " Name: tokenq1, Length: 283162, dtype: object,\n",
       " 'right': 297432                           [1, 1710, 11066, 115, 275]\n",
       " 309380    [22, 2, 3, 1999, 3, 1071, 4282, 159, 2615, 3, ...\n",
       " 186853               [1, 269, 33, 3, 660, 1081, 2512, 1064]\n",
       " 137620                          [22, 23, 24, 287, 92, 8353]\n",
       " 249535         [1, 2, 288, 2471, 2640, 159, 3, 1136, 13542]\n",
       " 10680     [2, 11318, 1308, 375, 3749, 489, 8025, 17, 242...\n",
       " 174864         [81, 24, 1497, 119, 27, 1728, 24, 139, 1347]\n",
       " 136616                       [72, 3, 3615, 57059, 384, 605]\n",
       " 71193     [47, 269, 971, 8190, 352, 1055, 1056, 2, 44, 8...\n",
       " 264191    [1, 115, 3, 9953, 3183, 4013, 34813, 72, 44, 7...\n",
       " 301288    [38, 94, 187, 24, 421, 309, 286, 46946, 47, 24...\n",
       " 19915                    [22, 23, 24, 412, 4944, 88, 19865]\n",
       " 261693    [274, 268, 5676, 482, 2401, 5, 5843, 342, 4410...\n",
       " 139222    [22, 94, 24, 97, 49, 662, 3218, 175, 54, 1523,...\n",
       " 191259    [17, 2299, 8, 3, 689, 2750, 316, 15, 305, 33, ...\n",
       " 45492                                [22, 23, 24, 103, 190]\n",
       " 99002     [1, 2, 1556, 11704, 8, 18, 2371, 47, 23, 44, 3...\n",
       " 135830    [300, 1273, 1274, 301, 593, 482, 475, 32240, 2...\n",
       " 173990    [24, 421, 26521, 2857, 12414, 31, 3, 1887, 110...\n",
       " 134638                            [22, 274, 8208, 1903, 34]\n",
       " 226411    [24, 39, 355, 108, 695, 2715, 17607, 108, 54, ...\n",
       " 240245     [22, 23, 24, 649, 4693, 1554, 175, 359, 24, 989]\n",
       " 19535     [373, 115, 116, 4637, 5435, 449, 2742, 8826, 1...\n",
       " 63937                      [1, 81, 24, 94, 3823, 175, 1409]\n",
       " 47687              [22, 300, 96, 130, 135, 136, 1144, 3127]\n",
       " 156253                             [22, 269, 1064, 658, 11]\n",
       " 266620    [22, 168, 1301, 197, 81, 54, 1409, 159, 49, 11...\n",
       " 142707    [6069, 4753, 50, 628, 29088, 2, 21520, 399, 28...\n",
       " 112497       [1, 2, 3, 1072, 219, 873, 54, 107, 5760, 3615]\n",
       " 289411             [94, 96, 421, 2065, 842, 4081, 22, 4588]\n",
       "                                 ...                        \n",
       " 299936    [94, 96, 315, 12296, 488, 17, 96, 1181, 10689,...\n",
       " 302882    [17, 47, 1187, 24, 94, 187, 11364, 27, 4361, 1...\n",
       " 158       [22, 94, 24, 271, 1052, 175, 27, 1055, 1056, 1...\n",
       " 37680                   [1, 2, 3, 180, 219, 278, 135, 2445]\n",
       " 306240    [1, 94, 3, 7693, 177, 163, 75, 3, 2676, 624, 1...\n",
       " 223217          [22, 23, 24, 45, 1124, 341, 1107, 8, 16660]\n",
       " 92704                     [22, 23, 24, 619, 18, 12210, 643]\n",
       " 159586                   [1, 115, 116, 407, 159, 4532, 972]\n",
       " 187839                             [22, 94, 96, 7318, 9320]\n",
       " 102353               [47, 300, 96, 226, 96, 3870, 33, 9314]\n",
       " 87443                    [22, 168, 474, 3708, 72, 169, 760]\n",
       " 143003     [22, 23, 96, 128, 1, 4497, 2983, 288, 833, 5620]\n",
       " 269533    [38, 115, 3, 9118, 3, 1154, 872, 38, 23, 187, ...\n",
       " 16587                        [38, 2, 169, 167, 1537, 8, 11]\n",
       " 122586                   [38, 2, 3, 5727, 22816, 167, 3129]\n",
       " 291397             [1, 2, 3, 1072, 219, 1134, 220, 88, 221]\n",
       " 293272                  [230, 3, 180, 1054, 108, 209, 2161]\n",
       " 305930                                    [1, 2, 84124, 19]\n",
       " 302181    [1, 94, 96, 267, 3, 1625, 5, 3, 2515, 7032, 33...\n",
       " 193936    [17, 169, 10379, 115, 167, 92, 81, 187, 148, 6...\n",
       " 115103                               [72, 2458, 3974, 2895]\n",
       " 76677                           [2, 3831, 3, 180, 2558, 19]\n",
       " 3206      [1, 115, 3, 872, 5278, 5279, 108, 49, 107, 54,...\n",
       " 17329                  [230, 44, 139, 920, 288, 2164, 1809]\n",
       " 191622    [1, 115, 3, 248, 27476, 3266, 3, 17873, 49, 10...\n",
       " 165744                  [1, 2, 92, 14091, 1927, 108, 20234]\n",
       " 279941    [230, 3, 4916, 2713, 108, 8685, 289, 315, 1007...\n",
       " 135461         [2, 54, 339, 17163, 18986, 660, 55908, 3278]\n",
       " 217091    [177, 74, 73, 40496, 3806, 42925, 668, 605, 73...\n",
       " 141662    [2, 962, 463, 920, 4261, 244, 4405, 2418, 4657...\n",
       " Name: tokenq2, Length: 283162, dtype: object}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#max_seq_length = max(token_train.tokenq1.map(lambda x: len(x)).max(),\n",
    "#                     token_train.tokenq2.map(lambda x: len(x)).max(),\n",
    "#                     token_test.tokenq1.map(lambda x: len(x)).max(),\n",
    "#                     token_test.tokenq2.map(lambda x: len(x)).max())\n",
    "max_seq_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Zero padding\n",
    "for dataset, side in itertools.product([X_train, X_validation], ['left', 'right']):\n",
    "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'left': array([[    0,     0,     0, ..., 17366,     2,    80],\n",
       "        [    0,     0,     0, ...,    18,  1071,  4282],\n",
       "        [    0,     1,   115, ...,  7783,   175,   688],\n",
       "        ..., \n",
       "        [    1,     2,     3, ...,    49, 17163, 18986],\n",
       "        [  527,   150,    17, ..., 27622,     2, 59569],\n",
       "        [  962,   463,   267, ...,   790,  9052,  5318]], dtype=int32),\n",
       " 'right': array([[    0,     0,     0, ..., 11066,   115,   275],\n",
       "        [    2,     3,  1999, ...,  2615,     3,  1145],\n",
       "        [    0,     0,     1, ...,  1081,  2512,  1064],\n",
       "        ..., \n",
       "        [    0,     0,     2, ...,   660, 55908,  3278],\n",
       "        [  527,   150,   311, ...,  2272,   527,   150],\n",
       "        [    2,   962,   463, ...,  2418,  4657,  5451]], dtype=int32)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert X_train['left'].shape == X_train['right'].shape\n",
    "assert len(X_train['left']) == len(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Failed to convert object of type <class 'tuple'> to Tensor. Contents: (array([ 1.42675461,  0.91187153,  0.73020944, ...,  0.94194277,\n       -0.32821698,  0.73846848]), 300). Consider casting elements to a supported type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m       \u001b[0mstr_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     64\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 65\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got array([ 1.42675461,  0.91187153,  0.73020944, ...,  0.94194277,\n       -0.32821698,  0.73846848])",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-926e755e7b97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m                 \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[1;32m    575\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/keras/layers/embeddings.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             dtype=self.dtype)\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         weight = K.variable(initializer(shape),\n\u001b[0m\u001b[1;32m    398\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/keras/initializers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         return K.random_uniform(shape, self.minval, self.maxval,\n\u001b[0;32m--> 107\u001b[0;31m                                 dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[1;32m   3629\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3630\u001b[0m     return tf.random_uniform(shape, minval=minval, maxval=maxval,\n\u001b[0;32m-> 3631\u001b[0;31m                              dtype=dtype, seed=seed)\n\u001b[0m\u001b[1;32m   3632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mmaxval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"random_uniform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ShapeTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0mminval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"min\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mmaxval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36m_ShapeTensor\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                          as_ref=False):\n\u001b[1;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    470\u001b[0m       raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\u001b[1;32m    471\u001b[0m                       \u001b[0;34m\"Contents: %s. Consider casting elements to a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m                       \"supported type.\" % (type(values), values))\n\u001b[0m\u001b[1;32m    473\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (array([ 1.42675461,  0.91187153,  0.73020944, ...,  0.94194277,\n       -0.32821698,  0.73846848]), 300). Consider casting elements to a supported type."
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "output_dim = 300\n",
    "input_dim = np.random.randn(len(vocabulary)) + 1\n",
    "\n",
    "model.add(Embedding(input_dim, output_dim, input_length=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3de995dd661e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.add(Embedding(input_dim, output_dim, input_length=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the embedding matrix\n",
    "embedding_dim = 300\n",
    "embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  # This will be the embedding matrix\n",
    "embeddings[0] = 0  # So that the padding will be ignored\n",
    "\n",
    "for word, index in vocabulary.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embeddings[index] = word2vec.word_vec(wor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#n_hidden = 50\n",
    "n_hidden = 1\n",
    "gradient_clipping_norm = 1.25\n",
    "#batch_size = 64\n",
    "batch_size = 1\n",
    "#n_epoch = 25\n",
    "n_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MaLSTM similarity function\n",
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    ''' Helper function for the similarity estimate of the LSTMs outputs'''\n",
    "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The visible layer\n",
    "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(len(embeddings), embedding_dim, weights=[embeddings], input_length=max_seq_length, trainable=False)\n",
    "\n",
    "# Embedded version of the inputs\n",
    "encoded_left = embedding_layer(left_input)\n",
    "encoded_right = embedding_layer(right_input)\n",
    "\n",
    "# Since this is a siamese network, both sides share the same LSTM\n",
    "shared_lstm = LSTM(n_hidden)\n",
    "\n",
    "left_output = shared_lstm(encoded_left)\n",
    "right_output = shared_lstm(encoded_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculates the distance as defined by the MaLSTM model\n",
    "malstm_distance = Merge(mode=lambda x: exponent_neg_manhattan_distance(x[0], x[1]), output_shape=lambda x: (x[0][0], 1))([left_output, right_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pack it all up into a model\n",
    "malstm = Model([left_input, right_input], [malstm_distance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adadelta optimizer, with gradient clipping by norm\n",
    "optimizer = Adadelta(clipnorm=gradient_clipping_norm)\n",
    "\n",
    "malstm.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "training_start_time = time()\n",
    "\n",
    "malstm_trained = malstm.fit([X_train['left'], X_train['right']], Y_train, batch_size=batch_size, epochs=n_epoch,\n",
    "                            validation_data=([X_validation['left'], X_validation['right']], Y_validation), validation_split = 0.2)\n",
    "\n",
    "print(\"Training time finished.\\n{} epochs in {}\".format(n_epoch, datetime.timedelta(seconds=time()-training_start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "plt.plot(malstm_trained.history['acc'])\n",
    "plt.plot(malstm_trained.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(malstm_trained.history['loss'])\n",
    "plt.plot(malstm_trained.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
