{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/mich/anaconda/envs/py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM, Merge\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train = pd.read_pickle(\"./data/df_train.pkl\")\n",
    "#df_test = pd.read_pickle(\"./data/df_test.pkl\")\n",
    "\n",
    "token_train = pd.read_pickle(\"./data/token_train.pkl\")\n",
    "token_test = pd.read_pickle(\"./data/token_test.pkl\")\n",
    "\n",
    "#vec_train = pd.read_pickle(\"./data/vec_train_glove.pkl\")\n",
    "#vec_test = pd.read_pickle(\"./data/vec_test_glove.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>tokenq1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>tokenq2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>241804</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[what, is, the, story, of, kohinoor, kohinoor,...</td>\n",
       "      <td>13483</td>\n",
       "      <td>[what, would, happen, if, the, indian, governm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[how, can, i, increase, the, speed, of, my, in...</td>\n",
       "      <td>241805</td>\n",
       "      <td>[how, can, internet, speed, be, increased, by,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[why, am, i, mentally, very, lonely, how, can,...</td>\n",
       "      <td>241806</td>\n",
       "      <td>[find, the, remainder, when, math, two, three,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[which, one, dissolve, in, water, quikly, suga...</td>\n",
       "      <td>241807</td>\n",
       "      <td>[which, fish, would, survive, in, salt, water]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1                                            tokenq1    qid2  \\\n",
       "0   0     0  [what, is, the, step, by, step, guide, to, inv...  241804   \n",
       "1   1     1  [what, is, the, story, of, kohinoor, kohinoor,...   13483   \n",
       "2   2     2  [how, can, i, increase, the, speed, of, my, in...  241805   \n",
       "3   3     3  [why, am, i, mentally, very, lonely, how, can,...  241806   \n",
       "4   4     4  [which, one, dissolve, in, water, quikly, suga...  241807   \n",
       "\n",
       "                                             tokenq2  is_duplicate  \n",
       "0  [what, is, the, step, by, step, guide, to, inv...             0  \n",
       "1  [what, would, happen, if, the, indian, governm...             0  \n",
       "2  [how, can, internet, speed, be, increased, by,...             0  \n",
       "3  [find, the, remainder, when, math, two, three,...             0  \n",
       "4     [which, fish, would, survive, in, salt, water]             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "googlenews_embedding = './data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(googlenews_embedding, binary=True)\n",
    "\n",
    "vocabulary = dict()\n",
    "inverse_vocabulary = ['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mich/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "questions = ['tokenq1', 'tokenq2']\n",
    "\n",
    "# Iterate over the questions of both training and test datasets\n",
    "for dataset in [token_train, token_test]:\n",
    "    for index, row in dataset.iterrows():\n",
    "\n",
    "        # Iterate through the text of both questions of the row\n",
    "        for question in questions:\n",
    "\n",
    "            question_to_number = []  # q2n -> question numbers representation\n",
    "            for word in row[question]:\n",
    "\n",
    "                # Check for unwanted words\n",
    "                if word in stops and word not in word2vec.vocab:\n",
    "                    continue\n",
    "\n",
    "                if word not in vocabulary:\n",
    "                    vocabulary[word] = len(inverse_vocabulary)\n",
    "                    question_to_number.append(len(inverse_vocabulary))\n",
    "                    inverse_vocabulary.append(word)\n",
    "                else:\n",
    "                    question_to_number.append(vocabulary[word])\n",
    "\n",
    "            # Replace questions as word to question as number representation\n",
    "            dataset.set_value(index, question, question_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>tokenq1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>tokenq2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 4, 6, 7, 8, 9, 10, 8, 11]</td>\n",
       "      <td>241804</td>\n",
       "      <td>[1, 2, 3, 4, 5, 4, 6, 7, 8, 9, 10]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 12, 13, 13, 14]</td>\n",
       "      <td>13483</td>\n",
       "      <td>[1, 15, 16, 17, 3, 18, 19, 20, 3, 13, 13, 14, 21]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[22, 23, 24, 25, 3, 26, 27, 28, 29, 30, 31, 32]</td>\n",
       "      <td>241805</td>\n",
       "      <td>[22, 23, 28, 26, 33, 34, 5, 35, 36, 37]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[38, 39, 24, 40, 41, 42, 22, 23, 24, 43, 44]</td>\n",
       "      <td>241806</td>\n",
       "      <td>[45, 3, 46, 47, 48, 49, 50, 49, 51, 48, 2, 52,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[53, 54, 55, 8, 56, 57, 58, 59, 60, 61, 62, 63]</td>\n",
       "      <td>241807</td>\n",
       "      <td>[53, 64, 15, 65, 8, 59, 56]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1                                          tokenq1    qid2  \\\n",
       "0   0     0        [1, 2, 3, 4, 5, 4, 6, 7, 8, 9, 10, 8, 11]  241804   \n",
       "1   1     1                        [1, 2, 3, 12, 13, 13, 14]   13483   \n",
       "2   2     2  [22, 23, 24, 25, 3, 26, 27, 28, 29, 30, 31, 32]  241805   \n",
       "3   3     3     [38, 39, 24, 40, 41, 42, 22, 23, 24, 43, 44]  241806   \n",
       "4   4     4  [53, 54, 55, 8, 56, 57, 58, 59, 60, 61, 62, 63]  241807   \n",
       "\n",
       "                                             tokenq2  is_duplicate  \n",
       "0                 [1, 2, 3, 4, 5, 4, 6, 7, 8, 9, 10]             0  \n",
       "1  [1, 15, 16, 17, 3, 18, 19, 20, 3, 13, 13, 14, 21]             0  \n",
       "2            [22, 23, 28, 26, 33, 34, 5, 35, 36, 37]             0  \n",
       "3  [45, 3, 46, 47, 48, 49, 50, 49, 51, 48, 2, 52,...             0  \n",
       "4                        [53, 64, 15, 65, 8, 59, 56]             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the embedding matrix\n",
    "embedding_dim = 300\n",
    "embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  # This will be the embedding matrix\n",
    "embeddings[0] = 0  # So that the padding will be ignored\n",
    "\n",
    "for word, index in vocabulary.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embeddings[index] = word2vec.word_vec(word)\n",
    "\n",
    "del word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split to train validation\n",
    "validation_size = 40000\n",
    "training_size = len(token_train) - validation_size\n",
    "\n",
    "question_cols = token_train[['tokenq1', 'tokenq2']]\n",
    "duplicate = token_train['is_duplicate']\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(question_cols, duplicate, test_size=validation_size)\n",
    "\n",
    "# Split to dicts\n",
    "X_train = {'left': X_train.tokenq1, 'right': X_train.tokenq2}\n",
    "X_validation = {'left': X_validation.tokenq1, 'right': X_validation.tokenq2}\n",
    "X_test = {'left': token_test.tokenq1, 'right': token_test.tokenq1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert labels to their numpy representations\n",
    "Y_train = Y_train.values\n",
    "Y_validation = Y_validation.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'left': 8199      [47, 269, 4349, 6503, 33, 3103, 108, 3, 3045, ...\n",
       " 190158    [1, 2, 3, 11927, 2616, 38, 2, 123, 2459, 8, 26...\n",
       " 31079        [373, 2, 3139, 3, 1593, 1594, 1184, 286, 1075]\n",
       " 212430         [22, 94, 24, 2312, 3, 3147, 615, 7001, 6116]\n",
       " 123395                    [38, 2, 169, 167, 215, 754, 1184]\n",
       " 55780                       [1, 115, 116, 8100, 1231, 1658]\n",
       " 44940     [1, 2, 3, 699, 3089, 108, 31, 1924, 8755, 1983...\n",
       " 133108                         [22, 115, 2406, 1313, 8, 11]\n",
       " 295125                       [230, 3, 180, 1812, 8, 3, 689]\n",
       " 129193                              [1, 115, 3, 2103, 3179]\n",
       " 251345                              [22, 81, 177, 976, 316]\n",
       " 64872                  [1, 2, 3, 180, 219, 1361, 159, 4084]\n",
       " 143778               [2, 3, 58488, 6558, 574, 3, 95, 24946]\n",
       " 282046                   [22, 23, 24, 5515, 675, 175, 4055]\n",
       " 43502     [22, 1107, 139, 8025, 17394, 115, 1001, 250, 4...\n",
       " 120147    [38, 94, 1990, 8, 3, 147, 36512, 97, 13949, 19...\n",
       " 11715                 [53, 2, 3, 180, 431, 108, 2566, 5274]\n",
       " 42062               [22, 23, 6123, 32024, 19982, 135, 8763]\n",
       " 167345    [1, 2, 44, 159, 80, 24277, 13022, 370, 12918, ...\n",
       " 161363    [439, 23, 24, 315, 1351, 1797, 8, 2442, 108, 1...\n",
       " 220433                    [22, 23, 305, 1811, 3, 689, 4201]\n",
       " 65431                  [22, 72, 1969, 1967, 141, 658, 4254]\n",
       " 248129       [22, 81, 24, 222, 108, 3809, 49, 107, 54, 627]\n",
       " 172966                       [22, 94, 24, 1239, 3094, 3015]\n",
       " 76408     [1, 115, 3, 1895, 6081, 1157, 7911, 1485, 15, ...\n",
       " 72111     [1, 115, 3, 1076, 2995, 3, 3593, 456, 11, 8, 3...\n",
       " 48090              [1, 4069, 12702, 6081, 115, 1477, 27753]\n",
       " 710                [2312, 73, 3051, 1903, 3051, 3052, 3053]\n",
       " 101096       [1, 2, 288, 15428, 1394, 2, 44, 718, 26, 1394]\n",
       " 119733    [1, 75, 903, 1266, 2137, 635, 8, 958, 439, 821...\n",
       "                                 ...                        \n",
       " 97247     [2300, 1, 2512, 17, 466, 72, 3, 3474, 48289, 4...\n",
       " 306257    [22, 72, 102, 8, 151, 3882, 159, 288, 4950, 54...\n",
       " 265898    [1, 2, 3, 1895, 248, 449, 566, 366, 4192, 431,...\n",
       " 117854            [23, 24, 94, 223, 164, 5426, 2777, 8, 11]\n",
       " 101045                [22, 94, 24, 15838, 108, 2295, 19694]\n",
       " 175126    [22, 168, 2269, 11086, 64283, 1670, 27067, 300...\n",
       " 41603                       [38, 94, 116, 177, 9360, 21750]\n",
       " 270542                   [1, 115, 116, 602, 512, 794, 8096]\n",
       " 229413    [22, 8195, 2, 3, 1560, 1204, 780, 8, 5153, 120...\n",
       " 249195       [22, 94, 24, 649, 27, 2841, 989, 3960, 8, 503]\n",
       " 44106                             [38, 94, 305, 1750, 1912]\n",
       " 173324                    [47, 72, 2826, 287, 3, 352, 2826]\n",
       " 31105               [421, 3, 4504, 10683, 276, 4810, 10684]\n",
       " 131878    [230, 3, 602, 1504, 38, 116, 708, 139, 2067, 783]\n",
       " 21719     [72, 3, 4271, 362, 7141, 8, 1204, 2312, 1082, ...\n",
       " 116649    [38, 274, 3, 3070, 3071, 580, 4165, 4298, 3067...\n",
       " 105707                       [72, 962, 2930, 1971, 8, 2743]\n",
       " 88165                             [46035, 7008, 7536, 3643]\n",
       " 276018              [1, 115, 3, 2182, 11765, 4336, 8, 2107]\n",
       " 64403                     [22, 94, 24, 133, 2818, 8, 11152]\n",
       " 33162                  [1, 115, 3, 815, 96, 2106, 1183, 38]\n",
       " 35456     [22, 115, 865, 841, 88, 3132, 3133, 487, 33, 3...\n",
       " 39415     [2111, 4654, 12707, 192, 6434, 1017, 1770, 555...\n",
       " 16422            [22, 94, 24, 4409, 503, 652, 416, 89, 362]\n",
       " 297954                       [269, 11, 8988, 637, 754, 807]\n",
       " 254243    [1, 115, 116, 794, 676, 14186, 578, 8, 3380, 512]\n",
       " 128236    [1, 94, 96, 267, 2, 3, 1779, 8509, 108, 3, 111...\n",
       " 13626                 [1, 94, 96, 267, 2, 3, 9726, 80, 857]\n",
       " 128304        [1, 2, 3, 768, 3, 1508, 5617, 175, 123, 4007]\n",
       " 249391    [2, 530, 602, 1067, 3504, 3, 195, 2685, 905, 4...\n",
       " Name: tokenq1, Length: 283162, dtype: object,\n",
       " 'right': 8199      [732, 1683, 1357, 812, 11, 3730, 175, 293, 306...\n",
       " 190158                [1, 2, 3, 216, 11927, 2616, 2623, 38]\n",
       " 31079     [373, 269, 1265, 3, 49, 107, 54, 628, 252, 253...\n",
       " 212430    [4114, 2, 288, 70676, 6544, 4620, 18071, 115, ...\n",
       " 123395                             [38, 2, 169, 167, 19660]\n",
       " 55780                 [1, 115, 116, 119, 23665, 1231, 1658]\n",
       " 44940     [1, 115, 3, 180, 3698, 33070, 108, 97, 584, 19...\n",
       " 133108                        [115, 275, 2406, 1313, 8, 11]\n",
       " 295125                  [1, 134, 135, 180, 1812, 8, 3, 689]\n",
       " 129193                               [1, 115, 3, 427, 3179]\n",
       " 251345                                   [22, 81, 177, 976]\n",
       " 64872                  [22, 72, 54, 1361, 159, 19741, 2642]\n",
       " 143778              [2, 58488, 6558, 574, 1115, 8084, 1452]\n",
       " 282046               [22, 23, 24, 25, 3, 675, 175, 27, 891]\n",
       " 43502     [22, 1107, 139, 8025, 17394, 250, 19793, 1457,...\n",
       " 120147          [38, 94, 187, 3, 147, 1990, 97, 53657, 809]\n",
       " 11715              [53, 115, 3, 180, 1213, 108, 2566, 5274]\n",
       " 42062                   [72, 6123, 32024, 19982, 135, 8763]\n",
       " 167345    [1, 2, 3, 763, 80, 12918, 220, 315, 141, 164, ...\n",
       " 161363    [439, 23, 24, 315, 1351, 1797, 8, 2442, 2428, ...\n",
       " 220433                                [81, 4201, 33, 37787]\n",
       " 65431             [1, 1069, 72, 1969, 4735, 421, 175, 4254]\n",
       " 248129    [22, 81, 24, 222, 108, 3809, 8541, 49, 107, 54...\n",
       " 172966                      [22, 23, 305, 1239, 3094, 3015]\n",
       " 76408        [38, 15, 237, 886, 88, 1157, 1053, 3050, 2711]\n",
       " 72111     [38, 11, 2, 167, 434, 192, 3715, 2, 44, 259, 1...\n",
       " 48090             [1, 115, 3, 248, 1253, 3880, 12702, 6081]\n",
       " 710       [94, 96, 315, 3021, 47, 96, 94, 3054, 3055, 17...\n",
       " 101096    [22, 23, 24, 1466, 116, 1095, 2345, 26, 1394, ...\n",
       " 119733                          [1, 513, 28336, 958, 11282]\n",
       "                                 ...                        \n",
       " 97247      [2, 275, 466, 2488, 558, 2300, 11899, 357, 1183]\n",
       " 306257    [53, 2, 3, 136, 102, 421, 2141, 1014, 2425, 1452]\n",
       " 265898                 [1, 2, 3, 566, 366, 4192, 4192, 146]\n",
       " 117854                   [23, 24, 94, 223, 164, 5426, 2777]\n",
       " 101045                 [22, 23, 24, 1361, 159, 2295, 19694]\n",
       " 175126    [2, 2131, 1287, 132, 286, 221, 22784, 229, 108...\n",
       " 41603                            [38, 94, 177, 9360, 21750]\n",
       " 270542       [230, 3, 180, 602, 512, 8096, 393, 394, 40434]\n",
       " 229413    [81, 24, 1409, 3, 48, 447, 1204, 384, 192, 148...\n",
       " 249195           [22, 94, 24, 649, 2841, 989, 3960, 8, 503]\n",
       " 44106              [38, 115, 3, 8806, 108, 1912, 167, 4534]\n",
       " 173324                       [47, 72, 2826, 287, 352, 2826]\n",
       " 31105         [274, 3, 4504, 14529, 3427, 276, 4810, 10684]\n",
       " 131878    [2, 44, 1948, 108, 782, 783, 33, 6967, 6977, 2...\n",
       " 21719     [44, 274, 276, 304, 73, 1543, 2, 394, 5501, 8,...\n",
       " 116649    [1, 1882, 1948, 159, 3067, 3068, 460, 3070, 24...\n",
       " 105707    [38, 72, 50324, 50325, 50326, 421, 288, 19761,...\n",
       " 88165     [1, 15, 33, 3, 180, 2857, 742, 40428, 10244, 1...\n",
       " 276018               [2, 44, 454, 20342, 288, 5593, 8, 190]\n",
       " 64403              [1, 2, 3, 180, 219, 133, 2818, 8, 11152]\n",
       " 33162     [1, 115, 3, 815, 96, 2106, 1183, 1993, 248, 45...\n",
       " 35456     [1, 269, 16, 865, 841, 8, 3, 147, 17, 1595, 11...\n",
       " 39415     [1, 115, 474, 3974, 3959, 11984, 3338, 2504, 8...\n",
       " 16422     [22, 23, 24, 649, 27, 503, 652, 416, 5560, 89,...\n",
       " 297954    [81, 11, 8988, 637, 754, 807, 460, 148, 115, 1...\n",
       " 254243         [1, 115, 116, 794, 9070, 1741, 8, 3380, 512]\n",
       " 128236                          [373, 2, 3, 1779, 8509, 11]\n",
       " 13626                              [1, 2, 3, 9726, 27, 857]\n",
       " 128304           [1, 2, 3, 768, 4648, 5617, 424, 123, 4007]\n",
       " 249391    [2, 530, 602, 1067, 3504, 3, 195, 2685, 905, 4...\n",
       " Name: tokenq2, Length: 283162, dtype: object}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#max_seq_length = max(token_train.tokenq1.map(lambda x: len(x)).max(),\n",
    "#                     token_train.tokenq2.map(lambda x: len(x)).max(),\n",
    "#                     token_test.tokenq1.map(lambda x: len(x)).max(),\n",
    "#                     token_test.tokenq2.map(lambda x: len(x)).max())\n",
    "max_seq_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Zero padding\n",
    "for dataset, side in itertools.product([X_train, X_validation], ['left', 'right']):\n",
    "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'left': array([[   0,    0,    0, ...,  628,   49,   51],\n",
       "        [   0,    0,    0, ..., 2623, 2616,  449],\n",
       "        [   0,    0,    0, ..., 1184,  286, 1075],\n",
       "        ..., \n",
       "        [   0,    0,    0, ..., 9726,   80,  857],\n",
       "        [   0,    0,    0, ...,  175,  123, 4007],\n",
       "        [   0,    0,    0, ..., 8039,  602, 1067]], dtype=int32),\n",
       " 'right': array([[    0,     0,   732, ...,   466,  3629, 13625],\n",
       "        [    0,     0,     0, ...,  2616,  2623,    38],\n",
       "        [    0,     0,     0, ...,  1184,   286,  1075],\n",
       "        ..., \n",
       "        [    0,     0,     0, ...,  9726,    27,   857],\n",
       "        [    0,     0,     0, ...,   424,   123,  4007],\n",
       "        [    0,     0,     0, ...,  1067,     8,  6954]], dtype=int32)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert X_train['left'].shape == X_train['right'].shape\n",
    "assert len(X_train['left']) == len(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#n_hidden = 50\n",
    "n_hidden = 1\n",
    "gradient_clipping_norm = 1.25\n",
    "#batch_size = 64\n",
    "batch_size = 1\n",
    "#n_epoch = 25\n",
    "n_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MaLSTM similarity function\n",
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    ''' Helper function for the similarity estimate of the LSTMs outputs'''\n",
    "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The visible layer\n",
    "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(len(embeddings), embedding_dim, weights=[embeddings], input_length=max_seq_length, trainable=False)\n",
    "\n",
    "# Embedded version of the inputs\n",
    "encoded_left = embedding_layer(left_input)\n",
    "encoded_right = embedding_layer(right_input)\n",
    "\n",
    "# Since this is a siamese network, both sides share the same LSTM\n",
    "shared_lstm = LSTM(n_hidden)\n",
    "\n",
    "left_output = shared_lstm(encoded_left)\n",
    "right_output = shared_lstm(encoded_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mich/anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Calculates the distance as defined by the MaLSTM model\n",
    "malstm_distance = Merge(mode=lambda x: exponent_neg_manhattan_distance(x[0], x[1]), output_shape=lambda x: (x[0][0], 1))([left_output, right_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pack it all up into a model\n",
    "malstm = Model([left_input, right_input], [malstm_distance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adadelta optimizer, with gradient clipping by norm\n",
    "optimizer = Adadelta(clipnorm=gradient_clipping_norm)\n",
    "\n",
    "malstm.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "training_start_time = time()\n",
    "\n",
    "malstm_trained = malstm.fit([X_train['left'], X_train['right']], Y_train, batch_size=batch_size, epochs=n_epoch,\n",
    "                            validation_data=([X_validation['left'], X_validation['right']], Y_validation), validation_split = 0.2)\n",
    "\n",
    "print(\"Training time finished.\\n{} epochs in {}\".format(n_epoch, datetime.timedelta(seconds=time()-training_start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "plt.plot(malstm_trained.history['acc'])\n",
    "plt.plot(malstm_trained.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(malstm_trained.history['loss'])\n",
    "plt.plot(malstm_trained.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
